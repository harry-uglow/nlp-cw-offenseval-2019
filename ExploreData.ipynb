{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "sentiment = 'subtask_a'\n",
    "(tweet_index, subtask_a_index) = (0, 1)\n",
    "tweet = 'tweet'\n",
    "num_features = 100  # Word vector dimensionality\n",
    "min_word_count = 10 # Minimum word count\n",
    "num_workers = 4     # Number of parallel threads\n",
    "context = 3         # Context window size\n",
    "downsampling = 1e-3 # (0.001) Downsample setting for frequent words\n",
    "name = f'num_features_{num_features}_min_word_count_{min_word_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence # we'll talk about this down below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(path_name, train):\n",
    "    path = './data/start-kit/'+path_name\n",
    "    df = pd.read_csv(path, sep='\\t', header=0 if train else None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_tweet_column(df, f, test=False):\n",
    "    indx = tweet if not test else tweet_index\n",
    "    df[indx] = df[indx].apply(f)\n",
    "    return df \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_sentence_vector(tweet, model, num_features):\n",
    "    #function to average all words vectors in a given tweet\n",
    "    words = tweet.split()\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            nwords = nwords+1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "\n",
    "    if nwords>0:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "def train_model(df, file_name):\n",
    "    tweets = df[tweet].map(lambda x: x.split())\n",
    "    print(\"Training model....\")\n",
    "    model = word2vec.Word2Vec(tweets,\n",
    "                          workers=num_workers,\n",
    "                          size=num_features,\n",
    "                          min_count=min_word_count,\n",
    "                          window=context,\n",
    "                          sample=downsampling)\n",
    "\n",
    "    # To make the model memory efficient\n",
    "    model.init_sims(replace=True)\n",
    "\n",
    "    # Saving the model for later use. Can be loaded using Word2Vec.load()\n",
    "    model_name = f'{num_features}features_{min_word_count}minwords_{context}context'\n",
    "    model.save(file_name+model_name)\n",
    "    \n",
    "    print('finished')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_and_preprocess_training_data(file_name):\n",
    "    df = load_data_from_file(file_name, True)\n",
    "    df.set_index('id')\n",
    "    df = df[[tweet, 'id', sentiment]]\n",
    "    df['pre_clean_len'] = [len(t) for t in df[tweet]]\n",
    "    df[sentiment]= df[sentiment].astype(str)\n",
    "    df = update_tweet_column(df, tweet_cleaner)\n",
    "    df['post_clean_len'] = [len(t) for t in df[tweet]]\n",
    "   \n",
    "    return df\n",
    "    \n",
    "    \n",
    "train_data = load_and_preprocess_training_data('training-v1/offenseval-training-v1.tsv')\n",
    "# \n",
    "train_data.head()\n",
    "model = train_model(train_data, './word2vec/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>pre_clean_len</th>\n",
       "      <th>post_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she should ask few native americans what their...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go home you re drunk maga trump url</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>67</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>182</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone should vetaken this piece of shit to v...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>65</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberals illegals to move into re...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet     id subtask_a  \\\n",
       "0  she should ask few native americans what their...  86426       OFF   \n",
       "1                go home you re drunk maga trump url  90194       OFF   \n",
       "2  amazon is investigating chinese employees who ...  16820       NOT   \n",
       "3  someone should vetaken this piece of shit to v...  62688       OFF   \n",
       "4  obama wanted liberals illegals to move into re...  43605       NOT   \n",
       "\n",
       "   pre_clean_len  post_clean_len  \n",
       "0             71              62  \n",
       "1             67              35  \n",
       "2            182             176  \n",
       "3             65              52  \n",
       "4             72              54  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86426</th>\n",
       "      <td>-0.025808</td>\n",
       "      <td>-0.053397</td>\n",
       "      <td>-0.071959</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>-0.037019</td>\n",
       "      <td>-0.011515</td>\n",
       "      <td>-0.060435</td>\n",
       "      <td>-0.014528</td>\n",
       "      <td>-0.054141</td>\n",
       "      <td>0.156113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.043734</td>\n",
       "      <td>-0.103292</td>\n",
       "      <td>0.095441</td>\n",
       "      <td>-0.086137</td>\n",
       "      <td>-0.167084</td>\n",
       "      <td>-0.083201</td>\n",
       "      <td>0.106072</td>\n",
       "      <td>-0.063322</td>\n",
       "      <td>-0.043647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90194</th>\n",
       "      <td>0.030471</td>\n",
       "      <td>-0.072112</td>\n",
       "      <td>-0.053726</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>-0.025430</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.013624</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>-0.008981</td>\n",
       "      <td>0.176921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085329</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.041904</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>-0.085861</td>\n",
       "      <td>-0.132010</td>\n",
       "      <td>-0.074978</td>\n",
       "      <td>0.103005</td>\n",
       "      <td>-0.056452</td>\n",
       "      <td>-0.002916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16820</th>\n",
       "      <td>0.003218</td>\n",
       "      <td>-0.037586</td>\n",
       "      <td>-0.056901</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>-0.045029</td>\n",
       "      <td>-0.012066</td>\n",
       "      <td>-0.062627</td>\n",
       "      <td>-0.022517</td>\n",
       "      <td>-0.027748</td>\n",
       "      <td>0.190147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024784</td>\n",
       "      <td>-0.036471</td>\n",
       "      <td>-0.061951</td>\n",
       "      <td>0.132558</td>\n",
       "      <td>-0.080589</td>\n",
       "      <td>-0.177264</td>\n",
       "      <td>-0.099771</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>-0.097557</td>\n",
       "      <td>-0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62688</th>\n",
       "      <td>0.006023</td>\n",
       "      <td>-0.052959</td>\n",
       "      <td>-0.089783</td>\n",
       "      <td>0.018669</td>\n",
       "      <td>-0.036615</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>-0.062124</td>\n",
       "      <td>-0.020938</td>\n",
       "      <td>-0.020009</td>\n",
       "      <td>0.149017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>-0.006138</td>\n",
       "      <td>-0.098574</td>\n",
       "      <td>0.106535</td>\n",
       "      <td>-0.075268</td>\n",
       "      <td>-0.162966</td>\n",
       "      <td>-0.085685</td>\n",
       "      <td>0.091813</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>-0.019161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43605</th>\n",
       "      <td>0.016144</td>\n",
       "      <td>-0.077130</td>\n",
       "      <td>-0.083577</td>\n",
       "      <td>0.022928</td>\n",
       "      <td>-0.066626</td>\n",
       "      <td>-0.016400</td>\n",
       "      <td>-0.051755</td>\n",
       "      <td>-0.026513</td>\n",
       "      <td>-0.034025</td>\n",
       "      <td>0.176835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>-0.005813</td>\n",
       "      <td>-0.103573</td>\n",
       "      <td>0.142955</td>\n",
       "      <td>-0.088360</td>\n",
       "      <td>-0.174962</td>\n",
       "      <td>-0.103088</td>\n",
       "      <td>0.109847</td>\n",
       "      <td>-0.079658</td>\n",
       "      <td>-0.000437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "id                                                                            \n",
       "86426 -0.025808 -0.053397 -0.071959  0.007813 -0.037019 -0.011515 -0.060435   \n",
       "90194  0.030471 -0.072112 -0.053726  0.001796 -0.025430 -0.022651 -0.013624   \n",
       "16820  0.003218 -0.037586 -0.056901  0.001754 -0.045029 -0.012066 -0.062627   \n",
       "62688  0.006023 -0.052959 -0.089783  0.018669 -0.036615  0.002618 -0.062124   \n",
       "43605  0.016144 -0.077130 -0.083577  0.022928 -0.066626 -0.016400 -0.051755   \n",
       "\n",
       "             7         8         9     ...           90        91        92  \\\n",
       "id                                     ...                                    \n",
       "86426 -0.014528 -0.054141  0.156113    ...    -0.000262 -0.043734 -0.103292   \n",
       "90194  0.012562 -0.008981  0.176921    ...     0.085329 -0.036498 -0.041904   \n",
       "16820 -0.022517 -0.027748  0.190147    ...     0.024784 -0.036471 -0.061951   \n",
       "62688 -0.020938 -0.020009  0.149017    ...     0.007430 -0.006138 -0.098574   \n",
       "43605 -0.026513 -0.034025  0.176835    ...     0.043138 -0.005813 -0.103573   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "id                                                                           \n",
       "86426  0.095441 -0.086137 -0.167084 -0.083201  0.106072 -0.063322 -0.043647  \n",
       "90194  0.094420 -0.085861 -0.132010 -0.074978  0.103005 -0.056452 -0.002916  \n",
       "16820  0.132558 -0.080589 -0.177264 -0.099771  0.093564 -0.097557 -0.007000  \n",
       "62688  0.106535 -0.075268 -0.162966 -0.085685  0.091813 -0.074811 -0.019161  \n",
       "43605  0.142955 -0.088360 -0.174962 -0.103088  0.109847 -0.079658 -0.000437  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_train_data(df):\n",
    "    df = df[[tweet, 'id']]\n",
    "    tweets = df[tweet].values\n",
    "    vectors = list(map(lambda x: avg_sentence_vector(x, model, num_features), tweets))\n",
    "    vectorised_df = pd.DataFrame(vectors)\n",
    "    vectorised_df = vectorised_df.set_index(df['id'], 'id')\n",
    "#     vectorised_df = df1.assign(e=p.Series(np.random.randn(sLength)).values)\n",
    "    vectorised_df.to_csv(f'./feature_vectors/train-word2vec-{name}.csv')\n",
    "    return vectorised_df\n",
    "train = save_train_data(train_data)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011055</td>\n",
       "      <td>-0.069653</td>\n",
       "      <td>-0.074623</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>-0.054083</td>\n",
       "      <td>-0.003010</td>\n",
       "      <td>-0.043216</td>\n",
       "      <td>-0.038179</td>\n",
       "      <td>-0.041985</td>\n",
       "      <td>0.146613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>-0.095614</td>\n",
       "      <td>0.110406</td>\n",
       "      <td>-0.078415</td>\n",
       "      <td>-0.152514</td>\n",
       "      <td>-0.102871</td>\n",
       "      <td>0.098589</td>\n",
       "      <td>-0.056031</td>\n",
       "      <td>-0.019192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.021337</td>\n",
       "      <td>-0.048995</td>\n",
       "      <td>-0.082546</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>-0.054076</td>\n",
       "      <td>-0.034848</td>\n",
       "      <td>-0.066061</td>\n",
       "      <td>-0.025940</td>\n",
       "      <td>-0.070016</td>\n",
       "      <td>0.142591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.117522</td>\n",
       "      <td>0.120904</td>\n",
       "      <td>-0.095736</td>\n",
       "      <td>-0.171728</td>\n",
       "      <td>-0.070688</td>\n",
       "      <td>0.111781</td>\n",
       "      <td>-0.067309</td>\n",
       "      <td>-0.028586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.022788</td>\n",
       "      <td>-0.054937</td>\n",
       "      <td>-0.073750</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>-0.042893</td>\n",
       "      <td>-0.006603</td>\n",
       "      <td>-0.072625</td>\n",
       "      <td>-0.018558</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>0.194205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>-0.048817</td>\n",
       "      <td>-0.089716</td>\n",
       "      <td>0.125778</td>\n",
       "      <td>-0.095211</td>\n",
       "      <td>-0.200785</td>\n",
       "      <td>-0.111419</td>\n",
       "      <td>0.117071</td>\n",
       "      <td>-0.089749</td>\n",
       "      <td>-0.028576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007014</td>\n",
       "      <td>-0.063645</td>\n",
       "      <td>-0.096343</td>\n",
       "      <td>0.021724</td>\n",
       "      <td>-0.041150</td>\n",
       "      <td>-0.016515</td>\n",
       "      <td>-0.045172</td>\n",
       "      <td>-0.023174</td>\n",
       "      <td>-0.022182</td>\n",
       "      <td>0.167480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031759</td>\n",
       "      <td>-0.012882</td>\n",
       "      <td>-0.094411</td>\n",
       "      <td>0.131319</td>\n",
       "      <td>-0.097340</td>\n",
       "      <td>-0.172573</td>\n",
       "      <td>-0.100675</td>\n",
       "      <td>0.120517</td>\n",
       "      <td>-0.049792</td>\n",
       "      <td>-0.010523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.014689</td>\n",
       "      <td>-0.054121</td>\n",
       "      <td>-0.068959</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>-0.074294</td>\n",
       "      <td>-0.034042</td>\n",
       "      <td>-0.079448</td>\n",
       "      <td>-0.035391</td>\n",
       "      <td>-0.075968</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017985</td>\n",
       "      <td>-0.031521</td>\n",
       "      <td>-0.111532</td>\n",
       "      <td>0.162854</td>\n",
       "      <td>-0.105122</td>\n",
       "      <td>-0.205485</td>\n",
       "      <td>-0.101574</td>\n",
       "      <td>0.112916</td>\n",
       "      <td>-0.101488</td>\n",
       "      <td>-0.017188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.011055 -0.069653 -0.074623  0.022289 -0.054083 -0.003010 -0.043216   \n",
       "1 -0.021337 -0.048995 -0.082546  0.005377 -0.054076 -0.034848 -0.066061   \n",
       "2 -0.022788 -0.054937 -0.073750  0.006791 -0.042893 -0.006603 -0.072625   \n",
       "3  0.007014 -0.063645 -0.096343  0.021724 -0.041150 -0.016515 -0.045172   \n",
       "4 -0.014689 -0.054121 -0.068959  0.003368 -0.074294 -0.034042 -0.079448   \n",
       "\n",
       "         7         8         9     ...           90        91        92  \\\n",
       "0 -0.038179 -0.041985  0.146613    ...     0.012440 -0.017667 -0.095614   \n",
       "1 -0.025940 -0.070016  0.142591    ...     0.006130 -0.018716 -0.117522   \n",
       "2 -0.018558 -0.045568  0.194205    ...     0.008616 -0.048817 -0.089716   \n",
       "3 -0.023174 -0.022182  0.167480    ...     0.031759 -0.012882 -0.094411   \n",
       "4 -0.035391 -0.075968  0.200693    ...     0.017985 -0.031521 -0.111532   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0  0.110406 -0.078415 -0.152514 -0.102871  0.098589 -0.056031 -0.019192  \n",
       "1  0.120904 -0.095736 -0.171728 -0.070688  0.111781 -0.067309 -0.028586  \n",
       "2  0.125778 -0.095211 -0.200785 -0.111419  0.117071 -0.089749 -0.028576  \n",
       "3  0.131319 -0.097340 -0.172573 -0.100675  0.120517 -0.049792 -0.010523  \n",
       "4  0.162854 -0.105122 -0.205485 -0.101574  0.112916 -0.101488 -0.017188  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_test_data():\n",
    "    df = load_data_from_file('trial-data/offenseval-trial.txt', False)\n",
    "    df = df[[tweet_index]]\n",
    "    df = update_tweet_column(df, tweet_cleaner, True)\n",
    "    tweets = df[tweet_index].values\n",
    "    vectors = list(map(lambda x: avg_sentence_vector(x, model, num_features), tweets))\n",
    "    vectorised_df = pd.DataFrame(vectors)\n",
    "    vectorised_df.to_csv(f'./feature_vectors/test-word2vec-{name}.csv', index_label='id')\n",
    "    return vectorised_df\n",
    "test = process_test_data()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
